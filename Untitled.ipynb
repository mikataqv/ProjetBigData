{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc6e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display\n",
    "import random\n",
    "import warnings\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv\n",
    "# sklearn Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Keras\n",
    "import keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras import layers\n",
    "from keras.layers.core import Activation, Dense, Dropout,  Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "117133ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66150,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66150,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66150,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66560,)\n",
      "(66560,)\n",
      "(66560,)\n",
      "(66560,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66560,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66327,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n",
      "(66150,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input signal length=0 is too small to resample from 44100->22050",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-db29a63a49e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'./genres/{g}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msoundname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'./genres/{g}/{filename}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoundname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecgram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNFFT\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoverlap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\a- programmes\\python\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\a- programmes\\python\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamplerate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconverter_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 584\u001b[1;33m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\a- programmes\\python\\lib\\site-packages\\resampy\\core.py\u001b[0m in \u001b[0;36mresample\u001b[1;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         raise ValueError('Input signal length={} is too small to '\n\u001b[1;32m---> 98\u001b[1;33m                          'resample from {}->{}'.format(x.shape[axis], sr_orig, sr_new))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m# Preserve contiguity of input (if it exists)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input signal length=0 is too small to resample from 44100->22050"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genres = 'ambulance firetruck traffic'.split()\n",
    "for g in genres:\n",
    "    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)\n",
    "    for filename in os.listdir(f'./genres/{g}'):\n",
    "        soundname = f'./genres/{g}/{filename}'\n",
    "        y, sr = librosa.load(soundname, mono=True, duration=5)\n",
    "        print(y.shape)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off');\n",
    "        plt.savefig(f'img_data/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eceacf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splitfolders.ratio('./img_data/', output=\"./data\", seed=1337, ratio=(.8, .2)) # default values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63202ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255, # rescale all pixel values from 0-255, so aftre this step all our pixel values are in range (0,1)\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2, #to apply some random tranfromations\n",
    "        zoom_range=0.2, #to apply zoom\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest') # image will be flipper horiz\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35283a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 480 images belonging to 3 classes.\n",
      "Found 120 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "        './data/train',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        './data/val',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6038140c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,936,707\n",
      "Trainable params: 1,936,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "input_shape=(64, 64,3)#1st hidden layer\n",
    "model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "\n",
    "model.add(Activation('relu'))#2nd hidden layer\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation('relu'))#3rd hidden layer\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation('relu'))#Flatten\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=0.5))#Add fully connected layer.\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.5))#Output layer\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "51caea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65b9111c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1866 - accuracy: 0.1930WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 1.1848 - accuracy: 0.1923 - val_loss: 1.0987 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1068 - accuracy: 0.2425\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1036 - accuracy: 0.2072\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1022 - accuracy: 0.2554\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1035 - accuracy: 0.2044\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.1009 - accuracy: 0.3820\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.1022 - accuracy: 0.2627\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0999 - accuracy: 0.3728\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1026 - accuracy: 0.2096\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0990 - accuracy: 0.4039\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1023 - accuracy: 0.2660\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.1000 - accuracy: 0.3436\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.1014 - accuracy: 0.2684\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1006 - accuracy: 0.3243\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.1012 - accuracy: 0.1760\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1017 - accuracy: 0.2108\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.1012 - accuracy: 0.2283\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0987 - accuracy: 0.4203\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.1002 - accuracy: 0.2791\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1009 - accuracy: 0.3361\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.1000 - accuracy: 0.4053\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0997 - accuracy: 0.3201\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.1006 - accuracy: 0.3691\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.1010 - accuracy: 0.2706\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1006 - accuracy: 0.2338\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1003 - accuracy: 0.2555\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.0980 - accuracy: 0.4508\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1008 - accuracy: 0.2589\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0991 - accuracy: 0.3959\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0980 - accuracy: 0.4634\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1009 - accuracy: 0.2397\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1006 - accuracy: 0.2560\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.1006 - accuracy: 0.2780\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1002 - accuracy: 0.3664\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.1005 - accuracy: 0.2990\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1017 - accuracy: 0.1890\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.1001 - accuracy: 0.2382\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1007 - accuracy: 0.2531\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.1016 - accuracy: 0.2084\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0997 - accuracy: 0.3792\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1001 - accuracy: 0.2827\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0970 - accuracy: 0.3000\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1000 - accuracy: 0.3203\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.1008 - accuracy: 0.2700\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1001 - accuracy: 0.3266\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.0997 - accuracy: 0.3525\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.1000 - accuracy: 0.2692\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0943 - accuracy: 0.3794\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0997 - accuracy: 0.2193 0s - loss: 1.0983 - \n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0996 - accuracy: 0.2941\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0999 - accuracy: 0.2706\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0989 - accuracy: 0.2742\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0972 - accuracy: 0.3807\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0895 - accuracy: 0.4550\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0985 - accuracy: 0.3281\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0962 - accuracy: 0.3178\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.0979 - accuracy: 0.3309\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.0974 - accuracy: 0.3177\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.0989 - accuracy: 0.3287\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 2s 105ms/step - loss: 1.0966 - accuracy: 0.3188\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0954 - accuracy: 0.3604\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 1.0941 - accuracy: 0.3969\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0928 - accuracy: 0.3777\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 1.0969 - accuracy: 0.3900\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0939 - accuracy: 0.3558\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0832 - accuracy: 0.3920\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.0843 - accuracy: 0.4144\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0919 - accuracy: 0.3860\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0897 - accuracy: 0.3584\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0867 - accuracy: 0.3922\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0824 - accuracy: 0.4280\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0884 - accuracy: 0.4005\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0842 - accuracy: 0.3576\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0879 - accuracy: 0.4280\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0802 - accuracy: 0.4786\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0942 - accuracy: 0.4304 0s - loss: 1.088\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0825 - accuracy: 0.4071\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0885 - accuracy: 0.3706\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1196 - accuracy: 0.3448\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0785 - accuracy: 0.3936\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.0498 - accuracy: 0.5513\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0835 - accuracy: 0.3976\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0751 - accuracy: 0.4225\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0505 - accuracy: 0.4763\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1125 - accuracy: 0.3592\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0632 - accuracy: 0.4768\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0544 - accuracy: 0.4760\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0967 - accuracy: 0.3022\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.0559 - accuracy: 0.3976\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0571 - accuracy: 0.4583\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0458 - accuracy: 0.4659\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 1.0532 - accuracy: 0.4804\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 1.0757 - accuracy: 0.4109\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0649 - accuracy: 0.3837\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0262 - accuracy: 0.5248\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.0158 - accuracy: 0.4831\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0208 - accuracy: 0.4842\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0200 - accuracy: 0.5041\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.0282 - accuracy: 0.4937\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.0095 - accuracy: 0.4911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x296404ece08>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(training_set,batch_size=64, epochs=100,   validation_data = test_set, verbose = 1, validation_steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e53244cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 31, 31, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 31, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 195       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 2,066,691\n",
      "Trainable params: 2,066,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "input_shape=(64, 64,3)#1st hidden layer\n",
    "model2.add(Conv2D(64, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "\n",
    "model2.add(Activation('relu'))#2nd hidden layer\n",
    "model2.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model2.add(Activation('relu'))#3rd hidden layer\n",
    "model2.add(MaxPooling2D(2,2))\n",
    "\n",
    "model2.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model2.add(Activation('relu'))#Flatten\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dropout(rate=0.5))#Add fully connected layer.\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(rate=0.5))#Output layer\n",
    "model2.add(Dense(3))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55ac64ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1181 - accuracy: 0.3777WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n",
      "15/15 [==============================] - 2s 144ms/step - loss: 1.1199 - accuracy: 0.3697 - val_loss: 1.0981 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.1114 - accuracy: 0.2185\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1054 - accuracy: 0.2312\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1021 - accuracy: 0.2634\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1019 - accuracy: 0.2841\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0982 - accuracy: 0.3133\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0970 - accuracy: 0.4598\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0980 - accuracy: 0.3701\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0998 - accuracy: 0.2951\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 1.0999 - accuracy: 0.3585\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1018 - accuracy: 0.2167\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0994 - accuracy: 0.3246\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1011 - accuracy: 0.2871\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0997 - accuracy: 0.3709\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0977 - accuracy: 0.3797\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1000 - accuracy: 0.3069\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1009 - accuracy: 0.2520\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0999 - accuracy: 0.2812\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1006 - accuracy: 0.2346\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.0977 - accuracy: 0.3335\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0984 - accuracy: 0.3192\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1009 - accuracy: 0.3064\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0928 - accuracy: 0.4815\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.0968 - accuracy: 0.3578\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0969 - accuracy: 0.3749\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1000 - accuracy: 0.3865\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0986 - accuracy: 0.3961\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.1008 - accuracy: 0.3197\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0973 - accuracy: 0.3873\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0972 - accuracy: 0.4085\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0995 - accuracy: 0.4124\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0927 - accuracy: 0.3828\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0974 - accuracy: 0.3719\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0957 - accuracy: 0.3343\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.0952 - accuracy: 0.3644\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0946 - accuracy: 0.3532\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0967 - accuracy: 0.3827\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0947 - accuracy: 0.3869\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.0923 - accuracy: 0.3827\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0974 - accuracy: 0.4311\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0844 - accuracy: 0.4568\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0986 - accuracy: 0.3356\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0942 - accuracy: 0.4230\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.0853 - accuracy: 0.4056\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0817 - accuracy: 0.3627\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0884 - accuracy: 0.4053\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0858 - accuracy: 0.4196\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0742 - accuracy: 0.4026\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1119 - accuracy: 0.3487\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0654 - accuracy: 0.3281\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0839 - accuracy: 0.4074\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0730 - accuracy: 0.4566\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0671 - accuracy: 0.4124\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0776 - accuracy: 0.3956\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0664 - accuracy: 0.4337\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0412 - accuracy: 0.4468\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0420 - accuracy: 0.4463\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0566 - accuracy: 0.3936\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0556 - accuracy: 0.4141\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0631 - accuracy: 0.3834\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0587 - accuracy: 0.3784\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0352 - accuracy: 0.4998\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0272 - accuracy: 0.4599\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0306 - accuracy: 0.4567\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.0423 - accuracy: 0.4675\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9560 - accuracy: 0.6597\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.2667 - accuracy: 0.4062\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0408 - accuracy: 0.4406\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1160 - accuracy: 0.3830\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0289 - accuracy: 0.4527\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0084 - accuracy: 0.4659\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0621 - accuracy: 0.4638\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0644 - accuracy: 0.4817\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0545 - accuracy: 0.4190\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9628 - accuracy: 0.5556\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9745 - accuracy: 0.5430\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0576 - accuracy: 0.4495\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.9940 - accuracy: 0.5480\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9608 - accuracy: 0.5685\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0291 - accuracy: 0.4737\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0090 - accuracy: 0.4283\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9946 - accuracy: 0.5306\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 1.0295 - accuracy: 0.4934\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0107 - accuracy: 0.4893\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9899 - accuracy: 0.5285\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9266 - accuracy: 0.5999\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9669 - accuracy: 0.6478\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9943 - accuracy: 0.5422\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0751 - accuracy: 0.4053\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0655 - accuracy: 0.4376\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9787 - accuracy: 0.5637\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9627 - accuracy: 0.5357\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9474 - accuracy: 0.5571\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0593 - accuracy: 0.4368\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9852 - accuracy: 0.5454\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9514 - accuracy: 0.5652\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9757 - accuracy: 0.5505\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9334 - accuracy: 0.5558\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9871 - accuracy: 0.5652\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0052 - accuracy: 0.5258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2dfb90c2648>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model2.fit(training_set,batch_size=64, epochs=100,   validation_data = test_set, verbose = 1, validation_steps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82b5e0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 31, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,938,691\n",
      "Trainable params: 1,938,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "input_shape=(64, 64,3)#1st hidden layer\n",
    "\n",
    "\n",
    "model3.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "model3.add(Activation('relu'))#2nd hidden layer\n",
    "model3.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model3.add(Activation('relu'))#Flatten\n",
    "model3.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model3.add(Activation('relu'))#3rd hidden layer\n",
    "model3.add(MaxPooling2D(2,2))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dropout(rate=0.5))#Add fully connected layer.\n",
    "model3.add(Dense(64))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dense(32))\n",
    "model3.add(Activation('relu'))\n",
    "model3.add(Dropout(rate=0.5))#Output layer\n",
    "model3.add(Dense(3))\n",
    "model3.add(Activation('softmax'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09def4b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1381 - accuracy: 0.2303WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "15/15 [==============================] - 4s 255ms/step - loss: 1.1379 - accuracy: 0.2311 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1066 - accuracy: 0.3211\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1043 - accuracy: 0.2757\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1047 - accuracy: 0.2216\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1039 - accuracy: 0.2547\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1010 - accuracy: 0.3032\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1008 - accuracy: 0.3096\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1041 - accuracy: 0.2814\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.1019 - accuracy: 0.2552\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1017 - accuracy: 0.2424\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0979 - accuracy: 0.4308\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1015 - accuracy: 0.2376\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1009 - accuracy: 0.2393\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0991 - accuracy: 0.3670\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1006 - accuracy: 0.3119\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1011 - accuracy: 0.2984\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0994 - accuracy: 0.3761\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1021 - accuracy: 0.2353\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0995 - accuracy: 0.2917\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1003 - accuracy: 0.2934\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1006 - accuracy: 0.2989\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1020 - accuracy: 0.2191\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1013 - accuracy: 0.2961\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1003 - accuracy: 0.2978\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1015 - accuracy: 0.2197\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1016 - accuracy: 0.2200\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1019 - accuracy: 0.2299\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1015 - accuracy: 0.2153\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0982 - accuracy: 0.4427\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1012 - accuracy: 0.2892\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1009 - accuracy: 0.2492\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1008 - accuracy: 0.2896\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0998 - accuracy: 0.2468\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0997 - accuracy: 0.3424\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1010 - accuracy: 0.2166\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0988 - accuracy: 0.4262\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1007 - accuracy: 0.2741\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1011 - accuracy: 0.2295\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1018 - accuracy: 0.2447\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1002 - accuracy: 0.3347\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1011 - accuracy: 0.1893\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1013 - accuracy: 0.1825\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1001 - accuracy: 0.3418\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1013 - accuracy: 0.1845\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0980 - accuracy: 0.4747\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 1.1008 - accuracy: 0.2894\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 1.1005 - accuracy: 0.2741\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 1.1016 - accuracy: 0.1861\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0995 - accuracy: 0.2658\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.1014 - accuracy: 0.2146\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0996 - accuracy: 0.3299\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0998 - accuracy: 0.2394\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0999 - accuracy: 0.2826\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1003 - accuracy: 0.2168\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1005 - accuracy: 0.2626\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0998 - accuracy: 0.3171\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1012 - accuracy: 0.2240\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1008 - accuracy: 0.2329\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0988 - accuracy: 0.3370\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1012 - accuracy: 0.1864\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0988 - accuracy: 0.3081\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1011 - accuracy: 0.2475\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1005 - accuracy: 0.2968\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.1008 - accuracy: 0.2746\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0996 - accuracy: 0.3259\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0998 - accuracy: 0.3163\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1008 - accuracy: 0.2864\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0990 - accuracy: 0.3256\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0993 - accuracy: 0.3148\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1002 - accuracy: 0.3152\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0999 - accuracy: 0.2512\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.1025 - accuracy: 0.2071\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0930 - accuracy: 0.4939\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.0985 - accuracy: 0.3812\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0979 - accuracy: 0.3348\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.1001 - accuracy: 0.2600\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0966 - accuracy: 0.3499\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0927 - accuracy: 0.4654\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0977 - accuracy: 0.3628\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0942 - accuracy: 0.4012\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0964 - accuracy: 0.3408\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0976 - accuracy: 0.3397\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0951 - accuracy: 0.4278\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0955 - accuracy: 0.3962\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0939 - accuracy: 0.3305\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1104 - accuracy: 0.3010\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0904 - accuracy: 0.4047\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0966 - accuracy: 0.2813\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0834 - accuracy: 0.4724\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0895 - accuracy: 0.3978\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0936 - accuracy: 0.3705\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0764 - accuracy: 0.4942\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0928 - accuracy: 0.3357\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0845 - accuracy: 0.3980\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0894 - accuracy: 0.3978\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0927 - accuracy: 0.3568\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0893 - accuracy: 0.3578\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0789 - accuracy: 0.4586\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0717 - accuracy: 0.5086\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0833 - accuracy: 0.3987\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0797 - accuracy: 0.4152\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0728 - accuracy: 0.4455\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0654 - accuracy: 0.4204\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0664 - accuracy: 0.4486\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0935 - accuracy: 0.3588\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0738 - accuracy: 0.4251\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0582 - accuracy: 0.3952\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1272 - accuracy: 0.4584\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0560 - accuracy: 0.4374\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0220 - accuracy: 0.4885\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0727 - accuracy: 0.4465\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0319 - accuracy: 0.4972\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0219 - accuracy: 0.5119\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0695 - accuracy: 0.3771\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0515 - accuracy: 0.4725\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0304 - accuracy: 0.5109\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0455 - accuracy: 0.4446\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0680 - accuracy: 0.4261\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0350 - accuracy: 0.4820\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1323 - accuracy: 0.3980\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0360 - accuracy: 0.4131\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9866 - accuracy: 0.6215\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1033 - accuracy: 0.3326\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0119 - accuracy: 0.4978\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0048 - accuracy: 0.5241\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0106 - accuracy: 0.4995\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9772 - accuracy: 0.5466\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9692 - accuracy: 0.4802\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9756 - accuracy: 0.5634\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0125 - accuracy: 0.4949\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9444 - accuracy: 0.5674\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9730 - accuracy: 0.5347\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9340 - accuracy: 0.5815\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9518 - accuracy: 0.5665\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9491 - accuracy: 0.5529\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9331 - accuracy: 0.5686\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0440 - accuracy: 0.4671\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9271 - accuracy: 0.5687\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9704 - accuracy: 0.5339\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9507 - accuracy: 0.5384\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9395 - accuracy: 0.6275\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9911 - accuracy: 0.5151\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0035 - accuracy: 0.4827\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.9686 - accuracy: 0.5461\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9449 - accuracy: 0.5543\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9466 - accuracy: 0.6138\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9038 - accuracy: 0.5978\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9310 - accuracy: 0.6211\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9596 - accuracy: 0.5805\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8819 - accuracy: 0.6181\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9492 - accuracy: 0.5276\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0040 - accuracy: 0.5003\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8964 - accuracy: 0.5796\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9438 - accuracy: 0.5660\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 2s 126ms/step - loss: 1.0143 - accuracy: 0.5479\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9799 - accuracy: 0.5509\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9036 - accuracy: 0.6352\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9796 - accuracy: 0.5215\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8868 - accuracy: 0.5934\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8478 - accuracy: 0.6303\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9254 - accuracy: 0.5927\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9613 - accuracy: 0.5227\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.7777 - accuracy: 0.6796\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9228 - accuracy: 0.5678\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9318 - accuracy: 0.6051\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9514 - accuracy: 0.5613\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8907 - accuracy: 0.6045\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9136 - accuracy: 0.5626\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9426 - accuracy: 0.5662\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9093 - accuracy: 0.5936\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8627 - accuracy: 0.6261\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8788 - accuracy: 0.6123\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8726 - accuracy: 0.6246\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.7947 - accuracy: 0.6805\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8491 - accuracy: 0.6511\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8546 - accuracy: 0.6528\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7852 - accuracy: 0.7198\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.8606 - accuracy: 0.5751\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9066 - accuracy: 0.6162\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8812 - accuracy: 0.6098\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 0.9048 - accuracy: 0.6076\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9032 - accuracy: 0.6112\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8243 - accuracy: 0.6592\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9018 - accuracy: 0.6098\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8932 - accuracy: 0.5846\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0416 - accuracy: 0.5445\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7904 - accuracy: 0.6640\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8969 - accuracy: 0.6526\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8077 - accuracy: 0.6856\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9125 - accuracy: 0.5839\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7436 - accuracy: 0.7062\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8331 - accuracy: 0.6521\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.6815 - accuracy: 0.7372\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9726 - accuracy: 0.5659\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8558 - accuracy: 0.6306\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.7141 - accuracy: 0.7251\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 0.8304 - accuracy: 0.6880\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8803 - accuracy: 0.6094\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.7687 - accuracy: 0.6664\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8328 - accuracy: 0.6271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x296353fad08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model3.fit(training_set,batch_size=64, epochs=200,   validation_data = test_set, verbose = 1, validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e5e9a700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.410495400428772, 0.8944099545478821]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate_generator(generator=test_set2, steps=len(test_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dcb3596e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 31, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,938,691\n",
      "Trainable params: 1,938,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "input_shape=(64, 64,3)#1st hidden layer\n",
    "\n",
    "\n",
    "model4.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "\n",
    "model4.add(Activation('relu'))#2nd hidden layer\n",
    "\n",
    "\n",
    "model4.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model4.add(Activation('relu'))#Flatten\n",
    "model4.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model4.add(Activation('relu'))#3rd hidden layer\n",
    "model4.add(MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "\n",
    "model4.add(Flatten())\n",
    "model4.add(Dropout(rate=0.2))#Add fully connected layer.\n",
    "model4.add(Dense(64))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dense(32))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(rate=0.2))#Output layer\n",
    "model4.add(Dense(3))\n",
    "model4.add(Activation('softmax'))\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "070c0938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1186 - accuracy: 0.4916WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "15/15 [==============================] - 2s 146ms/step - loss: 1.1196 - accuracy: 0.4898 - val_loss: 1.1088 - val_accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0875 - accuracy: 0.4461\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1179 - accuracy: 0.2587\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1036 - accuracy: 0.3255\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1087 - accuracy: 0.2044\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1040 - accuracy: 0.1997\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1042 - accuracy: 0.2435\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1048 - accuracy: 0.2521\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0999 - accuracy: 0.3738\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0999 - accuracy: 0.3157\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1026 - accuracy: 0.2513\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0979 - accuracy: 0.4378\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1020 - accuracy: 0.2736\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1001 - accuracy: 0.3366\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0998 - accuracy: 0.3406\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1010 - accuracy: 0.2183\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1010 - accuracy: 0.3241\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0992 - accuracy: 0.2341\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1004 - accuracy: 0.3442\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1025 - accuracy: 0.2785\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1017 - accuracy: 0.2154\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1017 - accuracy: 0.2542\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1010 - accuracy: 0.2509\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0989 - accuracy: 0.3455\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0982 - accuracy: 0.2933\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.1035 - accuracy: 0.2693\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0991 - accuracy: 0.3699\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1002 - accuracy: 0.3143\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1003 - accuracy: 0.3499\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0964 - accuracy: 0.4208\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.1002 - accuracy: 0.2775\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0947 - accuracy: 0.3455\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1009 - accuracy: 0.2517\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1060 - accuracy: 0.2534\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0963 - accuracy: 0.3532\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0947 - accuracy: 0.4177\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0963 - accuracy: 0.3354\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0964 - accuracy: 0.3500\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 2s 126ms/step - loss: 1.0933 - accuracy: 0.4588\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.0880 - accuracy: 0.5389\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0779 - accuracy: 0.4497\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0904 - accuracy: 0.4062\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0885 - accuracy: 0.3586\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0895 - accuracy: 0.4091\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.0831 - accuracy: 0.5052\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.0879 - accuracy: 0.4482\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0916 - accuracy: 0.4037\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.0876 - accuracy: 0.3494\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0804 - accuracy: 0.3726\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.0754 - accuracy: 0.3976\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0794 - accuracy: 0.3828\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0830 - accuracy: 0.4319\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0647 - accuracy: 0.4704\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0691 - accuracy: 0.5152\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0816 - accuracy: 0.3641\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0706 - accuracy: 0.4427\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0583 - accuracy: 0.4478\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0551 - accuracy: 0.5119\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.0635 - accuracy: 0.3795\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0646 - accuracy: 0.4093\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0635 - accuracy: 0.4366\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0549 - accuracy: 0.5059\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0576 - accuracy: 0.4695\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0549 - accuracy: 0.4033\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0374 - accuracy: 0.5338\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0672 - accuracy: 0.4295\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0302 - accuracy: 0.4689\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0474 - accuracy: 0.5487\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0466 - accuracy: 0.4472\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0141 - accuracy: 0.4710\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0397 - accuracy: 0.5028\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0169 - accuracy: 0.4477\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0566 - accuracy: 0.4213\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0080 - accuracy: 0.4742\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0154 - accuracy: 0.4602\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.9920 - accuracy: 0.4858\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0396 - accuracy: 0.4265\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0006 - accuracy: 0.5149\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0184 - accuracy: 0.4980\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0375 - accuracy: 0.4606\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0017 - accuracy: 0.4892\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0641 - accuracy: 0.5026\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0435 - accuracy: 0.4479\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0231 - accuracy: 0.4768\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0268 - accuracy: 0.4576\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9062 - accuracy: 0.6947\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0465 - accuracy: 0.4611\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9899 - accuracy: 0.4984\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0151 - accuracy: 0.4937\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0475 - accuracy: 0.4271\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9956 - accuracy: 0.5298\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9958 - accuracy: 0.5665\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0024 - accuracy: 0.4746\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9779 - accuracy: 0.5561\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0307 - accuracy: 0.4410\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.9696 - accuracy: 0.5035\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0204 - accuracy: 0.4403\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9629 - accuracy: 0.5867\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9954 - accuracy: 0.4864\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0159 - accuracy: 0.4835\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9595 - accuracy: 0.5822\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9034 - accuracy: 0.5494\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0075 - accuracy: 0.5101\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9694 - accuracy: 0.5086\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9406 - accuracy: 0.5960\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9695 - accuracy: 0.5742\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0068 - accuracy: 0.4749\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0018 - accuracy: 0.5402\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9286 - accuracy: 0.5458\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9185 - accuracy: 0.6418\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9013 - accuracy: 0.6019\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9605 - accuracy: 0.5410\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8844 - accuracy: 0.6410\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8821 - accuracy: 0.5778\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9752 - accuracy: 0.5492\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9279 - accuracy: 0.6087\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9106 - accuracy: 0.5895\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8736 - accuracy: 0.6435\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8736 - accuracy: 0.7341\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9089 - accuracy: 0.5775\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8671 - accuracy: 0.6154\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8695 - accuracy: 0.6228\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9002 - accuracy: 0.6105\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8466 - accuracy: 0.6519\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8811 - accuracy: 0.6109\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8210 - accuracy: 0.6469\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8987 - accuracy: 0.6267\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9245 - accuracy: 0.5778\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.9996 - accuracy: 0.5364\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9383 - accuracy: 0.5609\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9108 - accuracy: 0.6134\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8827 - accuracy: 0.6112\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9093 - accuracy: 0.6440\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7889 - accuracy: 0.6620\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8446 - accuracy: 0.6293\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8294 - accuracy: 0.6497\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8621 - accuracy: 0.6360\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7915 - accuracy: 0.6649\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8832 - accuracy: 0.5893\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8215 - accuracy: 0.6525\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8760 - accuracy: 0.6380\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8556 - accuracy: 0.6443\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.7907 - accuracy: 0.6838\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.8446 - accuracy: 0.6685\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 0.8205 - accuracy: 0.6608\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8597 - accuracy: 0.6424\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7404 - accuracy: 0.7010\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7499 - accuracy: 0.7072\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7947 - accuracy: 0.6857\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8303 - accuracy: 0.6265\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7580 - accuracy: 0.7051\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7971 - accuracy: 0.6830\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9125 - accuracy: 0.5851\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8272 - accuracy: 0.6142\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7450 - accuracy: 0.6646\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8337 - accuracy: 0.6445\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7884 - accuracy: 0.6787\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.7842 - accuracy: 0.6787\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8725 - accuracy: 0.5971\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8016 - accuracy: 0.6652\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8158 - accuracy: 0.7093\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.8068 - accuracy: 0.6481\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6873 - accuracy: 0.7285\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9165 - accuracy: 0.5941\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7780 - accuracy: 0.6246\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7123 - accuracy: 0.7023\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7392 - accuracy: 0.6815\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8672 - accuracy: 0.6201\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7992 - accuracy: 0.6425\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6109 - accuracy: 0.7721\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7942 - accuracy: 0.6664\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8168 - accuracy: 0.6202\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7758 - accuracy: 0.6577\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7487 - accuracy: 0.6868\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6886 - accuracy: 0.7281\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7931 - accuracy: 0.6440\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7023 - accuracy: 0.6998\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6554 - accuracy: 0.7429\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6325 - accuracy: 0.7469\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7182 - accuracy: 0.7108\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7650 - accuracy: 0.7338\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6761 - accuracy: 0.7119\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.6673 - accuracy: 0.7529\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7092 - accuracy: 0.7140\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7941 - accuracy: 0.6611\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7315 - accuracy: 0.6695\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6460 - accuracy: 0.7374\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6604 - accuracy: 0.7465\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6480 - accuracy: 0.7634\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6584 - accuracy: 0.7444\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7024 - accuracy: 0.7270\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6163 - accuracy: 0.7621\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8257 - accuracy: 0.6229\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6291 - accuracy: 0.7706\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 0.6274 - accuracy: 0.7588\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6714 - accuracy: 0.7175\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.5875 - accuracy: 0.7855\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6036 - accuracy: 0.7430\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6698 - accuracy: 0.7136\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6127 - accuracy: 0.7690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2963f865348>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model4.fit(training_set,batch_size=64, epochs=200,   validation_data = test_set, verbose = 1, validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aac6721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 31, 31, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 31, 31, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 31, 31, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                1843264   \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 99        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,938,691\n",
      "Trainable params: 1,938,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "input_shape=(64, 64,3)#1st hidden layer\n",
    "\n",
    "\n",
    "model5.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))\n",
    "\n",
    "model5.add(Activation('relu'))#2nd hidden layer\n",
    "\n",
    "\n",
    "model5.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model5.add(Activation('relu'))#Flatten\n",
    "model5.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model5.add(Activation('relu'))#3rd hidden layer\n",
    "model5.add(MaxPooling2D(2,2))\n",
    "\n",
    "\n",
    "\n",
    "model5.add(Flatten())\n",
    "model5.add(Dropout(rate=0.2))#Add fully connected layer.\n",
    "model5.add(Dense(64))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dense(32))\n",
    "model5.add(Activation('relu'))\n",
    "model5.add(Dropout(rate=0.2))#Output layer\n",
    "model5.add(Dense(3))\n",
    "model5.add(Activation('softmax'))\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d1b195d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.1466 - accuracy: 0.1624WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "15/15 [==============================] - 2s 145ms/step - loss: 1.1467 - accuracy: 0.1675 - val_loss: 1.0987 - val_accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0930 - accuracy: 0.5110\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1059 - accuracy: 0.3252\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1057 - accuracy: 0.2103\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1034 - accuracy: 0.2657\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1010 - accuracy: 0.3587\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1035 - accuracy: 0.2678\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1042 - accuracy: 0.2074\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1024 - accuracy: 0.2403\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0982 - accuracy: 0.3728\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1018 - accuracy: 0.3001\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1029 - accuracy: 0.2224\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1013 - accuracy: 0.2374\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1008 - accuracy: 0.2629\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1011 - accuracy: 0.3061\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1012 - accuracy: 0.2748\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1001 - accuracy: 0.3537\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1018 - accuracy: 0.2825\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0978 - accuracy: 0.2725\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0989 - accuracy: 0.4159\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1001 - accuracy: 0.3420\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1026 - accuracy: 0.3358\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1012 - accuracy: 0.2603\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1011 - accuracy: 0.2845\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0990 - accuracy: 0.3682\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0998 - accuracy: 0.3675\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0988 - accuracy: 0.3644\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1005 - accuracy: 0.2943\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0994 - accuracy: 0.4157\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1010 - accuracy: 0.2251\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1006 - accuracy: 0.2460\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1008 - accuracy: 0.2183\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.1012 - accuracy: 0.2547\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0969 - accuracy: 0.3828\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1011 - accuracy: 0.2138\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1016 - accuracy: 0.2255\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1001 - accuracy: 0.2893\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1006 - accuracy: 0.2878\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0957 - accuracy: 0.4102\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0989 - accuracy: 0.3279\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0997 - accuracy: 0.3637\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0923 - accuracy: 0.4445\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0986 - accuracy: 0.3755\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0960 - accuracy: 0.3408\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1025 - accuracy: 0.2237\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0974 - accuracy: 0.4179\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.1003 - accuracy: 0.3469\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0975 - accuracy: 0.3722\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0932 - accuracy: 0.4400\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1008 - accuracy: 0.3587\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0898 - accuracy: 0.3308\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1001 - accuracy: 0.3446\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0948 - accuracy: 0.3121\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0959 - accuracy: 0.3440\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0909 - accuracy: 0.4167\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0983 - accuracy: 0.3793\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0954 - accuracy: 0.4151\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0965 - accuracy: 0.3725\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0962 - accuracy: 0.3954\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0890 - accuracy: 0.4636\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0920 - accuracy: 0.3685\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0946 - accuracy: 0.3415\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0840 - accuracy: 0.3890\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0899 - accuracy: 0.3252\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0894 - accuracy: 0.4078\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.0869 - accuracy: 0.4131\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0944 - accuracy: 0.3822\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1066 - accuracy: 0.3289\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0794 - accuracy: 0.3804\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0904 - accuracy: 0.3613\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0931 - accuracy: 0.3509\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0772 - accuracy: 0.3850\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0883 - accuracy: 0.3362\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0755 - accuracy: 0.4741\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0726 - accuracy: 0.4432\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0720 - accuracy: 0.4684\n",
      "Epoch 77/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0679 - accuracy: 0.4222\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0676 - accuracy: 0.4677\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 1.0839 - accuracy: 0.3561\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0674 - accuracy: 0.4597\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0607 - accuracy: 0.4780\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0601 - accuracy: 0.4595\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0514 - accuracy: 0.4671\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0791 - accuracy: 0.3579\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9839 - accuracy: 0.6539\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.2138 - accuracy: 0.2638\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0561 - accuracy: 0.3395\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.1049 - accuracy: 0.3543\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0599 - accuracy: 0.4272\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0405 - accuracy: 0.4569\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0596 - accuracy: 0.3831\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0192 - accuracy: 0.4897\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.1080 - accuracy: 0.3731\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0070 - accuracy: 0.4957\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9759 - accuracy: 0.5254\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0947 - accuracy: 0.3610\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0660 - accuracy: 0.4577\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0055 - accuracy: 0.4829\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 1.0480 - accuracy: 0.4107\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 2s 126ms/step - loss: 1.0366 - accuracy: 0.4181\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0324 - accuracy: 0.5148\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0256 - accuracy: 0.4082\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0551 - accuracy: 0.4210\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9921 - accuracy: 0.4732\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9508 - accuracy: 0.5857\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9993 - accuracy: 0.5228\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0105 - accuracy: 0.4956\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.2000 - accuracy: 0.3183\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0906 - accuracy: 0.4099\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9812 - accuracy: 0.4955\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0188 - accuracy: 0.4594\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9592 - accuracy: 0.4701\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.0525 - accuracy: 0.4082\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9773 - accuracy: 0.5057\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9606 - accuracy: 0.5099\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.9831 - accuracy: 0.4848\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9396 - accuracy: 0.5618\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0490 - accuracy: 0.4469\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 1.0852 - accuracy: 0.4735\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9688 - accuracy: 0.4979\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9625 - accuracy: 0.5419\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9766 - accuracy: 0.4874\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9723 - accuracy: 0.4995\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 1.0021 - accuracy: 0.4487\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9693 - accuracy: 0.5391\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9349 - accuracy: 0.5861\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9143 - accuracy: 0.5831\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 0.8879 - accuracy: 0.6245\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8848 - accuracy: 0.5817\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9601 - accuracy: 0.5461\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8964 - accuracy: 0.6349\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8646 - accuracy: 0.6400\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.9064 - accuracy: 0.5706\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 2s 131ms/step - loss: 0.7939 - accuracy: 0.6523\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 2s 141ms/step - loss: 0.9996 - accuracy: 0.5120\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 1.0072 - accuracy: 0.4784\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9829 - accuracy: 0.5488\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9258 - accuracy: 0.5804\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8619 - accuracy: 0.6190\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9004 - accuracy: 0.6165\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8695 - accuracy: 0.6007\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7667 - accuracy: 0.6911\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9325 - accuracy: 0.5445\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.9003 - accuracy: 0.5908\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8894 - accuracy: 0.5907\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8886 - accuracy: 0.6567\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7795 - accuracy: 0.6961\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.9832 - accuracy: 0.5041\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.9371 - accuracy: 0.5473\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8794 - accuracy: 0.6013\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8394 - accuracy: 0.6230\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.9196 - accuracy: 0.5639\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9109 - accuracy: 0.5422\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.9251 - accuracy: 0.5725\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8595 - accuracy: 0.6403\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 126ms/step - loss: 0.8446 - accuracy: 0.6413\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.7667 - accuracy: 0.6991\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 0.7440 - accuracy: 0.7197\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.8298 - accuracy: 0.6352\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.7807 - accuracy: 0.6770\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8656 - accuracy: 0.6891\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8429 - accuracy: 0.6503\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8003 - accuracy: 0.6689\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.8996 - accuracy: 0.5912\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.9170 - accuracy: 0.5732\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 0.8319 - accuracy: 0.6645\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 0.6997 - accuracy: 0.7200\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7498 - accuracy: 0.6891\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8896 - accuracy: 0.5950\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 2s 120ms/step - loss: 0.8170 - accuracy: 0.6766\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8641 - accuracy: 0.5958\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7928 - accuracy: 0.6936\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.8525 - accuracy: 0.6461\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6936 - accuracy: 0.7405\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8623 - accuracy: 0.6334\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6709 - accuracy: 0.7665\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7362 - accuracy: 0.7123\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7773 - accuracy: 0.6912\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8691 - accuracy: 0.6404\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.6770 - accuracy: 0.7107\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7891 - accuracy: 0.6749\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7493 - accuracy: 0.6870\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7212 - accuracy: 0.6818\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.8131 - accuracy: 0.6662\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 0.6784 - accuracy: 0.7241\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7550 - accuracy: 0.6768\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7920 - accuracy: 0.6921\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8615 - accuracy: 0.6240\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7306 - accuracy: 0.6634\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7553 - accuracy: 0.7211\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6924 - accuracy: 0.7266\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.7026 - accuracy: 0.7166\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.5405 - accuracy: 0.7898\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6664 - accuracy: 0.7367\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.5464 - accuracy: 0.8107\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6609 - accuracy: 0.7309\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.7394 - accuracy: 0.7097\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 2s 121ms/step - loss: 0.6963 - accuracy: 0.7298\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 2s 119ms/step - loss: 0.6694 - accuracy: 0.7261\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 2s 118ms/step - loss: 0.8787 - accuracy: 0.5783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29640a37848>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "model5.fit(training_set,batch_size=64, epochs=200,   validation_data = test_set, verbose = 1, validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b7dc23bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9368007779121399, 0.45962733030319214]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate_generator(generator=test_set2, steps=len(test_set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "daad1fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fd612152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model5.predict(test_set, steps=len(test_set), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c1ae2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "predictions = predictions[:200]\n",
    "filenames=test_set.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1754eed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"prediction_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "79b734dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Filename Predictions\n",
      "0    ambulance\\sound_102.png   ambulance\n",
      "1    ambulance\\sound_113.png   firetruck\n",
      "2    ambulance\\sound_123.png     traffic\n",
      "3    ambulance\\sound_126.png   ambulance\n",
      "4    ambulance\\sound_137.png   ambulance\n",
      "..                       ...         ...\n",
      "115    traffic\\sound_579.png     traffic\n",
      "116    traffic\\sound_582.png     traffic\n",
      "117    traffic\\sound_588.png     traffic\n",
      "118    traffic\\sound_590.png     traffic\n",
      "119    traffic\\sound_597.png     traffic\n",
      "\n",
      "[120 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "file = \"prediction_results.csv\"\n",
    "df = pd.read_csv(file)\n",
    "pd.options.display.max_columns = len(df.columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6077247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110250,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "soundname = f'ambulance_test.wav'\n",
    "y, sr = librosa.load(soundname, mono=True, duration=5)\n",
    "print(y.shape)\n",
    "plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, sides='default', mode='default', scale='dB');\n",
    "plt.axis('off');\n",
    "plt.savefig(f'{filename[:-3].replace(\".\", \"\")}.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "10a480c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set2 = test_datagen.flow_from_directory(\n",
    "        './testeu',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f9fb7238",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.31602675 0.08674517 0.5972281 ]\n",
      " [0.17171629 0.06132022 0.7669635 ]\n",
      " [0.2819206  0.06608819 0.65199125]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "predict=model3.predict(test_set2, steps=len(test_set2))\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56a803cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\taqua\\AppData\\Local\\Temp\\tmpc3665hdq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\taqua\\AppData\\Local\\Temp\\tmpc3665hdq\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1950592"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model3)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "tflite_model=converter.convert()\n",
    "open(\"converted_model3.tflite\",\"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2106c4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\taqua\\AppData\\Local\\Temp\\tmpoud8l0n9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\taqua\\AppData\\Local\\Temp\\tmpoud8l0n9\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7758572"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model3)\n",
    "\n",
    "tflite_model=converter.convert()\n",
    "open(\"converted_model3.tflite\",\"wb\").write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
